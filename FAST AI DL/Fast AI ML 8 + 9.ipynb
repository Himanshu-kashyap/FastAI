{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fast AI ML 8 + 9.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/fastai/fastai/blob/master/courses/ml1/lesson4-mnist_sgd.ipynb","timestamp":1544443311162}],"collapsed_sections":["0WYBtcIFidd-","ykldENNdideA","JRSML0HlideX","5d1IkWGNideb","1sM847VxidfA","iSKpGgK2idf2","LHEx3V6bidgF","WlsbsCu4idg4","tuIIRtApidhh","CUXew8Wkidhn"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"DJLqBiVKALK2","colab_type":"text"},"cell_type":"markdown","source":["# MNIST\n","\n"]},{"metadata":{"id":"DbiCpDM4idY7","colab_type":"code","outputId":"e18ed94e-c123-4d69-e44e-aec57c6243e0","executionInfo":{"status":"ok","timestamp":1544482563646,"user_tz":-330,"elapsed":2191,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"metadata":{"id":"dWsReEz9_p-2","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install Pillow==4.1.1\n","!pip install \"fastai==0.7.0\"\n","!pip install torchtext==0.2.3\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E6ZN-sciidZA","colab_type":"code","colab":{}},"cell_type":"code","source":["from fastai.imports import *\n","from fastai.torch_imports import *\n","from fastai.io import *"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wIXUX4Y6idZF","colab_type":"code","colab":{}},"cell_type":"code","source":["path = 'data/mnist/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KdlF4TPjidZK","colab_type":"text"},"cell_type":"markdown","source":["Let's download, unzip, and format the data."]},{"metadata":{"id":"cfp7r2SUidZL","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","os.makedirs(path, exist_ok=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2mZIGmW7idZP","colab_type":"code","colab":{}},"cell_type":"code","source":["URL='http://deeplearning.net/data/mnist/'\n","FILENAME='mnist.pkl.gz'\n","\n","def load_mnist(filename):\n","    return pickle.load(gzip.open(filename, 'rb'), encoding='latin-1')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wo_a8106idZX","colab_type":"code","colab":{}},"cell_type":"code","source":["get_data(URL+FILENAME, path+FILENAME)\n","((x, y), (x_valid, y_valid), _) = load_mnist(path+FILENAME)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KLVwd9xxidZf","colab_type":"code","outputId":"5e0fe4eb-5946-47f0-f7df-b1941277505a","executionInfo":{"status":"ok","timestamp":1544482574482,"user_tz":-330,"elapsed":12838,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["type(x), x.shape, type(y), y.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(numpy.ndarray, (50000, 784), numpy.ndarray, (50000,))"]},"metadata":{"tags":[]},"execution_count":48}]},{"metadata":{"id":"Xd0wVgVCidZo","colab_type":"text"},"cell_type":"markdown","source":["### Normalize"]},{"metadata":{"id":"eDKULvPpidZq","colab_type":"text"},"cell_type":"markdown","source":["Many machine learning algorithms behave better when the data is *normalized*, that is when the mean is 0 and the standard deviation is 1. We will subtract off the mean and standard deviation from our training set in order to normalize the data:"]},{"metadata":{"id":"CqvJxOghE97u","colab_type":"text"},"cell_type":"markdown","source":["scaling is by the pixels"]},{"metadata":{"id":"9556tMChidZr","colab_type":"code","outputId":"a6f049c0-ca7a-427a-e1f7-ca694458ade7","executionInfo":{"status":"ok","timestamp":1544482574908,"user_tz":-330,"elapsed":13235,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["mean = x.mean()\n","std = x.std()\n","\n","x=(x-mean)/std\n","mean, std, x.mean(), x.std()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.13044983, 0.3072898, -3.1638146e-07, 0.99999934)"]},"metadata":{"tags":[]},"execution_count":49}]},{"metadata":{"id":"NPOk8__WidZu","colab_type":"text"},"cell_type":"markdown","source":["Note that for consistency (with the parameters we learn when training), we subtract the mean and standard deviation of our training set from our validation set. "]},{"metadata":{"id":"6rmSX3c0idZv","colab_type":"code","outputId":"15150f26-ad7e-47cd-86c7-630f529feb8e","executionInfo":{"status":"ok","timestamp":1544482574910,"user_tz":-330,"elapsed":13209,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["'''\n","We are normalizing based on training set mean and std dev\n","as we are needed both set of numbers to be in same scale \n","diff val and train set means diff scale of same numbers in \n","diff dataset hence different final values\n","\n","\n","'''\n","\n","x_valid = (x_valid-mean)/std\n","x_valid.mean(), x_valid.std()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(-0.005850922, 0.99243325)"]},"metadata":{"tags":[]},"execution_count":50}]},{"metadata":{"id":"e3VEmwS_idZz","colab_type":"text"},"cell_type":"markdown","source":["### Look at the data"]},{"metadata":{"id":"b-nyJCDkidZ2","colab_type":"text"},"cell_type":"markdown","source":["In any sort of data science work, it's important to look at your data, to make sure you understand the format, how it's stored, what type of values it holds, etc. To make it easier to work with, let's reshape it into 2d images from the flattened 1d format."]},{"metadata":{"id":"puVDW7pGidZ3","colab_type":"text"},"cell_type":"markdown","source":["#### Helper methods"]},{"metadata":{"id":"NJPVPAHYidZ6","colab_type":"code","colab":{}},"cell_type":"code","source":["def show(img, title=None):\n","    plt.imshow(img, cmap=\"gray\")\n","    if title is not None: plt.title(title)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SEBX5h9ridZ9","colab_type":"code","colab":{}},"cell_type":"code","source":["def plots(ims, figsize=(12,6), rows=2, titles=None):\n","    f = plt.figure(figsize=figsize)\n","    cols = len(ims)//rows\n","    for i in range(len(ims)):\n","        sp = f.add_subplot(rows, cols, i+1)\n","        sp.axis('Off')\n","        if titles is not None: sp.set_title(titles[i], fontsize=16)\n","        plt.imshow(ims[i], cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j0mgFT-LidaE","colab_type":"text"},"cell_type":"markdown","source":["#### Plots "]},{"metadata":{"id":"6p-4zwgUidaE","colab_type":"code","outputId":"fb036b42-549d-4823-9e19-945714f6968f","executionInfo":{"status":"ok","timestamp":1544482575563,"user_tz":-330,"elapsed":13756,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["x_valid.shape # the images are in shape of 1d tensor there are 10k images"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 784)"]},"metadata":{"tags":[]},"execution_count":53}]},{"metadata":{"id":"E3r-S7kAidaP","colab_type":"code","outputId":"9e0064af-52e5-42de-b9a4-0862ee9f23e8","executionInfo":{"status":"ok","timestamp":1544482575568,"user_tz":-330,"elapsed":13711,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["'''\n","numpy reshapes 1d tensor to 2d and can take input of only 1 dimension as\n","it only needs n-1 dimensions out of n. last can be figured out. \n","\n","-1 means how large or small can it go to fit. it's actual value is 10k\n","\n","\n","(-1,28,28)\n","All neural networks, the first axis is a row, image, a sentence, \n","example, then we reshape the last two axis\n","\n","'''\n","\n","x_imgs = np.reshape(x_valid, (-1,28,28)); x_imgs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":54}]},{"metadata":{"id":"HbFQ2EOjidaS","colab_type":"code","outputId":"4b9c1333-ae4c-4891-9739-fa35cd66ad9b","executionInfo":{"status":"ok","timestamp":1544482575572,"user_tz":-330,"elapsed":13667,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":280}},"cell_type":"code","source":["show(x_imgs[0], y_valid[0])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPoAAAEHCAYAAACHl1tOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noKCLBKCgiwSgoIsEoKCLBKCgiwTwfzrYKoW62D0ZAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7fa62e5e8748>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"BNjcid_nidaZ","colab_type":"code","outputId":"6b37315f-bb33-4901-cffc-f28e27a805cc","executionInfo":{"status":"ok","timestamp":1544482575575,"user_tz":-330,"elapsed":13622,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["y_valid.shape #rank 1 tensor"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000,)"]},"metadata":{"tags":[]},"execution_count":56}]},{"metadata":{"id":"N3fb2Fapidae","colab_type":"text"},"cell_type":"markdown","source":["It's the digit 3!  And that's stored in the y value:"]},{"metadata":{"id":"VJgnmCDOidaf","colab_type":"code","outputId":"368d2554-fb3c-4335-c8d0-b0a5d7639e0b","executionInfo":{"status":"ok","timestamp":1544482575576,"user_tz":-330,"elapsed":13579,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["y_valid[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{"tags":[]},"execution_count":57}]},{"metadata":{"id":"UUbIiGCwidal","colab_type":"text"},"cell_type":"markdown","source":["We can look at part of an image:"]},{"metadata":{"id":"U0cDOM4Sidan","colab_type":"code","outputId":"8982c51c-9fda-438d-8af1-b425e43f33a5","executionInfo":{"status":"ok","timestamp":1544482575579,"user_tz":-330,"elapsed":13557,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"cell_type":"code","source":["x_imgs[0,10:15,10:15] # slicing 1st axis with 0  converting 3d matrix to 2d matrix"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.42452, -0.42452, -0.42452, -0.42452,  0.17294],\n","       [-0.42452, -0.42452, -0.42452,  0.78312,  2.43567],\n","       [-0.42452, -0.27197,  1.20261,  2.77889,  2.80432],\n","       [-0.42452,  1.76194,  2.80432,  2.80432,  1.73651],\n","       [-0.42452,  2.20685,  2.80432,  2.80432,  0.40176]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":58}]},{"metadata":{"id":"rc7mMmm_idat","colab_type":"code","outputId":"616d05f2-b9b2-4c30-c998-2b1d350b6291","executionInfo":{"status":"ok","timestamp":1544482575970,"user_tz":-330,"elapsed":13922,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":265}},"cell_type":"code","source":["show(x_imgs[0,10:15,10:15])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPQAAAD4CAYAAADb7cuFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n","text/plain":["<matplotlib.figure.Figure at 0x7fa62e4f4160>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"JBLAXpzwidbC","colab_type":"code","outputId":"75283965-769f-4bfa-b167-4f1ed4226463","executionInfo":{"status":"ok","timestamp":1544482576708,"user_tz":-330,"elapsed":14629,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":409}},"cell_type":"code","source":["plots(x_imgs[:8], titles=y_valid[:8])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAr4AAAF0CAYAAADFHDo6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n05z4VcPCAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7fa6307619e8>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"nG4jZmb-idbK","colab_type":"text"},"cell_type":"markdown","source":["## Neural Networks"]},{"metadata":{"id":"iJW4HihUidbO","colab_type":"text"},"cell_type":"markdown","source":["We will take a deep look *logistic regression* and how we can program it ourselves. We are going to treat it as a specific example of a shallow neural net."]},{"metadata":{"id":"CeUxMIDkidbR","colab_type":"text"},"cell_type":"markdown","source":["**What is a neural network?**\n","\n","A *neural network* is an *infinitely flexible function*, consisting of *layers*.  A *layer* is a linear function such as matrix multiplication followed by a non-linear function (the *activation*).\n","\n","One of the tricky parts of neural networks is just keeping track of all the vocabulary! "]},{"metadata":{"id":"BbkWY8-MidbS","colab_type":"text"},"cell_type":"markdown","source":["### Functions, parameters, and training"]},{"metadata":{"id":"Snj8-wghidbU","colab_type":"text"},"cell_type":"markdown","source":["A **function** takes inputs and returns outputs. For instance, $f(x) = 3x + 5$ is an example of a function.  If we input $2$, the output is $3\\times 2 + 5 = 11$, or if we input $-1$, the output is $3\\times -1 + 5 = 2$\n","\n","Functions have **parameters**. The above function $f$ is $ax + b$, with parameters a and b set to $a=3$ and $b=5$.\n","\n","Machine learning is often about learning the best values for those parameters.  For instance, suppose we have the data points on the chart below.  What values should we choose for $a$ and $b$?"]},{"metadata":{"id":"UwFZdYM7idbW","colab_type":"text"},"cell_type":"markdown","source":["<img src=\"https://github.com/fastai/fastai/blob/master/courses/ml1/images/sgd2.gif?raw=1\" alt=\"\" style=\"width: 70%\"/>"]},{"metadata":{"id":"uK5wtIFIidbX","colab_type":"text"},"cell_type":"markdown","source":["In the above gif from fast.ai's deep learning course, [intro to SGD notebook](https://github.com/fastai/courses/blob/master/deeplearning1/nbs/sgd-intro.ipynb)), an algorithm called stochastic gradient descent is being used to learn the best parameters to fit the line to the data (note: in the gif, the algorithm is stopping before the absolute best parameters are found).  This process is called **training** or **fitting**.\n","\n","Most datasets will not be well-represented by a line.  We could use a more complicated function, such as $g(x) = ax^2 + bx + c + \\sin d$.  Now we have 4 parameters to learn: $a$, $b$, $c$, and $d$.  This function is more flexible than $f(x) = ax + b$ and will be able to accurately model more datasets.\n","\n","Neural networks take this to an extreme, and are infinitely flexible.  They often have thousands, or even hundreds of thousands of parameters.  However the core idea is the same as above.  The neural network is a function, and we will learn the best parameters for modeling our data."]},{"metadata":{"id":"7_rY0an9IM-4","colab_type":"text"},"cell_type":"markdown","source":["we are gonna use neural network to fit the line as it is inf flexible fxn"]},{"metadata":{"id":"G3FWNivLidbX","colab_type":"text"},"cell_type":"markdown","source":["### PyTorch"]},{"metadata":{"id":"TSk3RHdWidba","colab_type":"text"},"cell_type":"markdown","source":["\n","The fastai deep learning library uses [PyTorch](http://pytorch.org/), a Python framework for dynamic neural networks with GPU acceleration, which was released by Facebook's AI team.\n","\n","PyTorch has two overlapping, yet distinct, purposes.  As described in the [PyTorch documentation](http://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html):\n","\n","<img src=\"https://github.com/fastai/fastai/blob/master/courses/ml1/images/what_is_pytorch.png?raw=1\" alt=\"pytorch\" style=\"width: 80%\"/>\n","\n","The neural network functionality of PyTorch is built on top of the Numpy-like functionality for fast matrix computations on a GPU. Although the neural network purpose receives way more attention, both are very useful.  We'll implement a neural net from scratch today using PyTorch.\n","\n","**Further learning**: If you are curious to learn what *dynamic* neural networks are, you may want to watch [this talk](https://www.youtube.com/watch?v=Z15cBAuY7Sc) by Soumith Chintala, Facebook AI researcher and core PyTorch contributor.\n","\n","If you want to learn more PyTorch, you can try this [introductory tutorial](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) or this [tutorial to learn by examples](http://pytorch.org/tutorials/beginner/pytorch_with_examples.html)."]},{"metadata":{"id":"p46JdZ7zidbh","colab_type":"text"},"cell_type":"markdown","source":["## Neural Net for Logistic Regression in PyTorch"]},{"metadata":{"id":"Q2hU4TVCidbi","colab_type":"code","colab":{}},"cell_type":"code","source":["from fastai.metrics import *\n","from fastai.model import *\n","from fastai.dataset import *\n","\n","import torch.nn as nn"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xqD2RFbGidbm","colab_type":"text"},"cell_type":"markdown","source":["We will begin with the highest level abstraction: using a neural net defined by PyTorch's Sequential class.  "]},{"metadata":{"id":"uA2EPXOiidbn","colab_type":"code","outputId":"4ec77381-8f06-4e28-b563-7ccff59069a8","executionInfo":{"status":"ok","timestamp":1544482576715,"user_tz":-330,"elapsed":14476,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# creating a neural nw in pytorch\n","# seq = you give layer names which needed to be included\n","\n","net = nn.Sequential(\n","    nn.Linear(28*28, 10),  # y= ax+b matrix product output of size 100\n","    \n","    nn.LogSoftmax() # need non linearity after linear layer\n",").cuda()\n","\n","# loss fxn is used to define inf gain the score of how good we are\n","\n","# ouput will be the number of classes taken to classify 10 0 to 9 \n","# 0 is cat and 6 is dog etc\n","\n","\n","'''\n","this will build simple logistic regression\n","\n","'''"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nthis will build simple logistic regression\\n\\n'"]},"metadata":{"tags":[]},"execution_count":62}]},{"metadata":{"id":"rqQPA8vua3vZ","colab_type":"code","colab":{}},"cell_type":"code","source":["'''\n","use this or above but this is better\n","\n","this one adds another hidden layer\n","\n","'''\n","net = nn.Sequential(\n","    nn.Linear(28*28, 100),  # y= ax+b matrix product output of size 100\n","    nn.ReLU(),\n","    nn.Linear(100,10),\n","    nn.LogSoftmax() # need non linearity after linear layer\n",").cuda()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U44so05zidbq","colab_type":"text"},"cell_type":"markdown","source":["Each input is a vector of size `28*28` pixels and our output is of size `10` (since there are 10 digits: 0, 1, ..., 9). \n","\n","We use the output of the final layer to generate our predictions.  Often for classification problems (like MNIST digit classification), the final layer has the same number of outputs as there are classes.  In that case, this is 10: one for each digit from 0 to 9.  These can be converted to comparative probabilities.  For instance, it may be determined that a particular hand-written image is 80% likely to be a 4, 18% likely to be a 9, and 2% likely to be a 3."]},{"metadata":{"id":"MxEROJboidbr","colab_type":"code","colab":{}},"cell_type":"code","source":["'''\n","path =  temp locn to save values\n","x,y :: training data\n","\n","It takes mini batch and makes them variable\n","\n","'''\n","md = ImageClassifierData.from_arrays(path, (x,y), (x_valid, y_valid))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WlhLMaFNidbv","colab_type":"code","colab":{}},"cell_type":"code","source":["loss=nn.NLLLoss()  # negative log likelihood loss or cross entropy\n","metrics=[accuracy]\n","# opt=optim.SGD(net.parameters(), 1e-1, momentum=0.9)\n","opt=optim.SGD(net.parameters(), 1e-1, momentum=0.9, weight_decay=1e-3)\n","\n","# Nll or cross entropy is of 2 types binary and categorical we using \n","# binary which is for only 2 items.\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8tjqT0Csidby","colab_type":"text"},"cell_type":"markdown","source":["### Loss functions and metrics"]},{"metadata":{"id":"KaoaNQIhidby","colab_type":"text"},"cell_type":"markdown","source":["In machine learning the **loss** function or cost function is representing the price paid for inaccuracy of predictions.\n","\n","The loss associated with one example in binary classification is given by:\n","`-(y * log(p) + (1-y) * log (1-p))`\n","where `y` is the true label of `x` and `p` is the probability predicted by our model that the label is 1."]},{"metadata":{"id":"ngYS0qgKidb0","colab_type":"code","colab":{}},"cell_type":"code","source":["'''\n","acts 1 = cat 0 = dog \n","and predictions 90 cat 10 dog 20 cat 80 dog\n","1st and 2nd predic will op same values as it is \n","log of pred and log \n","\n","y can be only 0 or 1 so can use if statement\n","as the mult is by 0\n","\n","\n","'''\n","\n","def binary_loss(y, p):\n","    return np.mean(-(y * np.log(p) + (1-y)*np.log(1-p)))\n","  \n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"W6W7G4VIidb3","colab_type":"code","outputId":"3c4701b8-96d6-497f-b5b6-ecfc359200c1","executionInfo":{"status":"ok","timestamp":1544482577201,"user_tz":-330,"elapsed":14880,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["'''\n","in case of determining how far a prediction is from actual i.e. \n","we predicting cat dog and plane how far is cat prediction from \n","reality: plane. \n","\n","we use one hot encoding  category    cat dog plane  probability      calc binary entropy \n","                            plane    0    0   1    (of being a plane)      value\n","\n","categorical entropy = sum(binary entropies of all numbers/ categories 0 to 9)\n","i.e 10 predictions\n","\n","\n","\n","'''\n","\n","\n","\n","acts = np.array([1, 0, 0, 1])\n","preds = np.array([0.9, 0.1, 0.2, 0.8])\n","binary_loss(acts, preds)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.164252033486018"]},"metadata":{"tags":[]},"execution_count":66}]},{"metadata":{"id":"5UPz7TCjidcD","colab_type":"text"},"cell_type":"markdown","source":["Note that in our toy example above our accuracy is 100% and our loss is 0.16. Compare that to a loss of 0.03 that we are getting while predicting cats and dogs. Exercise: play with `preds` to get a lower loss for this example. \n","\n","**Example:** Here is an example on how to compute the loss for one example of binary classification problem. Suppose for an image x with label 1 and your model gives it a prediction of 0.9. For this case the loss should be small because our model is predicting a label $1$ with high probability.\n","\n","`loss = -log(0.9) = 0.10`\n","\n","Now suppose x has label 0 but our model is predicting 0.9. In this case our loss is should be much larger.\n","\n","`loss = -log(1-0.9) = 2.30`\n","\n","- Exercise: look at the other cases and convince yourself that this make sense.\n","- Exercise: how would you rewrite `binary_loss` using `if` instead of `*` and `+`?\n","\n","Why not just maximize accuracy? The binary classification loss is an easier function to optimize.\n","\n","For multi-class classification, we use *negative log liklihood* (also known as *categorical cross entropy*) which is exactly the same thing, but summed up over all classes."]},{"metadata":{"id":"7DBd9R-5idcE","colab_type":"text"},"cell_type":"markdown","source":["### Fitting the model"]},{"metadata":{"id":"rwJh8jMvidcF","colab_type":"text"},"cell_type":"markdown","source":["*Fitting* is the process by which the neural net learns the best parameters for the dataset."]},{"metadata":{"id":"ScrzhbquidcH","colab_type":"code","outputId":"3b42f6e2-88fc-4dd1-d678-5933bfeaff04","executionInfo":{"status":"ok","timestamp":1544482612442,"user_tz":-330,"elapsed":50086,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"cell_type":"code","source":["fit(net, md, n_epochs=5, crit=loss, opt=opt, metrics=metrics)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2166607aad749f9ac9adbeecdb0066e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["epoch      trn_loss   val_loss   accuracy   \n","    0      1.252922   1.614048   0.8372    \n","    1      1.28945    1.212888   0.8566    \n","    2      1.185147   0.990395   0.8848    \n","    3      1.184262   1.079819   0.8759    \n","    4      1.388976   1.237042   0.8642    \n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[array([1.23704]), 0.8642]"]},"metadata":{"tags":[]},"execution_count":67}]},{"metadata":{"id":"1m5rIvuhidcT","colab_type":"code","colab":{}},"cell_type":"code","source":["set_lrs(opt, 1e-2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"weRuvBEDidcb","colab_type":"code","outputId":"97de9c69-f0c8-4e77-e95c-dd9c0a0a1dc4","executionInfo":{"status":"ok","timestamp":1544482635561,"user_tz":-330,"elapsed":73161,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":159}},"cell_type":"code","source":["fit(net, md, n_epochs=3, crit=loss, opt=opt, metrics=metrics)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10494ff936584a1f83814ed1e9869708","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Epoch', max=3, style=ProgressStyle(description_width='initial"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["epoch      trn_loss   val_loss   accuracy   \n","    0      0.487398   0.466385   0.9214    \n","    1      0.344212   0.361717   0.9234    \n","    2      0.305332   0.328788   0.9241    \n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[array([0.32879]), 0.9241]"]},"metadata":{"tags":[]},"execution_count":69}]},{"metadata":{"id":"tU07MXY5idcj","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"k7KE86Hcidcr","colab_type":"code","outputId":"064321ae-8161-49aa-d2d7-d4c2477b6f0a","executionInfo":{"status":"ok","timestamp":1544482669473,"user_tz":-330,"elapsed":107013,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"cell_type":"code","source":["fit(net, md, n_epochs=5, crit=loss, opt=opt, metrics=metrics)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2512810ad8e64a80a9b0aa955d7d34a9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["epoch      trn_loss   val_loss   accuracy   \n","    0      0.328449   0.30939    0.9221    \n","    1      0.318823   0.292995   0.9224    \n","    2      0.283714   0.296238   0.9212    \n","    3      0.293835   0.298435   0.9183    \n","    4      0.306891   0.292576   0.9174    \n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[array([0.29258]), 0.9174]"]},"metadata":{"tags":[]},"execution_count":70}]},{"metadata":{"id":"JDSNetuwidcw","colab_type":"code","colab":{}},"cell_type":"code","source":["set_lrs(opt, 1e-2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oXRYUGQXidcy","colab_type":"code","outputId":"e6086254-7d3a-4aa2-a67e-b19e400c057c","executionInfo":{"status":"ok","timestamp":1544482689050,"user_tz":-330,"elapsed":126487,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":159}},"cell_type":"code","source":["fit(net, md, n_epochs=3, crit=loss, opt=opt, metrics=metrics)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ce6069578184b7abfd3000eb564c772","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Epoch', max=3, style=ProgressStyle(description_width='initial"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["epoch      trn_loss   val_loss   accuracy   \n","    0      0.278651   0.290759   0.9176    \n","    1      0.276023   0.280852   0.9228    \n","    2      0.263586   0.274007   0.9247    \n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[array([0.27401]), 0.9247]"]},"metadata":{"tags":[]},"execution_count":72}]},{"metadata":{"id":"zVfiBfUYidc3","colab_type":"code","outputId":"6e83c6a0-31ee-4844-e97b-c2969de7c0b2","executionInfo":{"status":"ok","timestamp":1544482689362,"user_tz":-330,"elapsed":126751,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["t = [o.numel() for o in net.parameters()]\n","t, sum(t)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([7840, 10], 7850)"]},"metadata":{"tags":[]},"execution_count":73}]},{"metadata":{"id":"dC6D78mSidc5","colab_type":"text"},"cell_type":"markdown","source":["GPUs are great at handling lots of data at once (otherwise don't get performance benefit).  We break the data up into **batches**, and that specifies how many samples from our dataset we want to send to the GPU at a time.  The fastai library defaults to a batch size of 64.  On each iteration of the training loop, the error on 1 batch of data will be calculated, and the optimizer will update the parameters based on that.\n","\n","An **epoch** is completed once each data sample has been used once in the training loop.\n","\n","Now that we have the parameters for our model, we can make predictions on our validation set."]},{"metadata":{"id":"G8AoTXbWidc6","colab_type":"code","colab":{}},"cell_type":"code","source":["preds = predict(net, md.val_dl)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z6LtT-3pidc9","colab_type":"code","outputId":"c70b25ca-c338-4ab3-bb79-dac24cf0c7d9","executionInfo":{"status":"ok","timestamp":1544482689692,"user_tz":-330,"elapsed":127009,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["preds.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 10)"]},"metadata":{"tags":[]},"execution_count":75}]},{"metadata":{"id":"9wPLB6RfiddE","colab_type":"text"},"cell_type":"markdown","source":["**Question**: Why does our output have length 10 (for each image)?\n","\n","10k images for validation \n","we make 10 predictions per image"]},{"metadata":{"id":"OzFdl7reiddE","colab_type":"code","outputId":"e799de86-77f2-4e9f-8d11-9fb892c1fc7f","executionInfo":{"status":"ok","timestamp":1544482689694,"user_tz":-330,"elapsed":126979,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["preds.argmax(axis=1)[:5]  # tke arr of preds find highest val index\n","# grab first 5 in col and print max index"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 8, 6, 9, 6])"]},"metadata":{"tags":[]},"execution_count":76}]},{"metadata":{"id":"auK3DQYyiddH","colab_type":"code","colab":{}},"cell_type":"code","source":["preds = preds.argmax(1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kPN9huqqiddJ","colab_type":"text"},"cell_type":"markdown","source":["Let's check how accurate this approach is on our validation set. You may want to compare this against other implementations of logistic regression, such as the one in sklearn. In our testing, this simple pytorch version is faster and more accurate for this problem!"]},{"metadata":{"id":"FtYz-wxpiddK","colab_type":"code","outputId":"666a702e-3271-47ce-fa4a-cdd9b2485a03","executionInfo":{"status":"ok","timestamp":1544482689697,"user_tz":-330,"elapsed":126921,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["np.mean(preds == y_valid)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9247"]},"metadata":{"tags":[]},"execution_count":78}]},{"metadata":{"id":"jNpJxIfMiddR","colab_type":"text"},"cell_type":"markdown","source":["Let's see how some of our predictions look!"]},{"metadata":{"id":"aWY9h8igiddT","colab_type":"code","outputId":"ab4b04c3-94e5-4694-810a-f85ac03fdf86","executionInfo":{"status":"ok","timestamp":1544482690806,"user_tz":-330,"elapsed":127991,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":409}},"cell_type":"code","source":["plots(x_imgs[:8], titles=preds[:8])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAr4AAAF0CAYAAADFHDo6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n05z4VcPCAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7fa62b987320>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"5OrtuqEBiddW","colab_type":"text"},"cell_type":"markdown","source":["## Defining Logistic Regression Ourselves"]},{"metadata":{"id":"CeHQW2y4iddZ","colab_type":"text"},"cell_type":"markdown","source":["Above, we used pytorch's `nn.Linear` to create a linear layer.  This is defined by a matrix multiplication and then an addition (these are also called `affine transformations`).  Let's try defining this ourselves.\n","\n","Just as Numpy has `np.matmul` for matrix multiplication (in Python 3, this is equivalent to the `@` operator), PyTorch has `torch.matmul`.  \n","\n","Our PyTorch class needs two things: constructor (says what the parameters are) and a forward method (how to calculate a prediction using those parameters)  The method `forward` describes how the neural net converts inputs to outputs.\n","\n","In PyTorch, the optimizer knows to try to optimize any attribute of type **Parameter**."]},{"metadata":{"id":"WdCJdCx8iddZ","colab_type":"code","colab":{}},"cell_type":"code","source":["'''\n","torch.randn builds number with random dist\n","in dl if we increase no. of layers weight matrix is of appropriate size\n","so it does not cause any prob in future when there is change in input\n","mean of input to matrix does not change so we divide by dims[0]\n","\n","it will basically generate numbers with mean =0 std dev = 1\n","\n","'''\n","\n","def get_weights(*dims): return nn.Parameter(torch.randn(dims)/dims[0])\n","# param tells which things to update when it does stoc grad desc\n","\n","def softmax(x): return torch.exp(x)/(torch.exp(x).sum(dim=1)[:,None])\n","\n","\n","'''\n","creating a pytorch module\n","\n","\n","bias as in y = mx+ b(bias)\n","different for every pt\n","\n","'''\n","\n","\n","# superclass nn.Module is inherited by logreg \n","class LogReg(nn.Module):\n","    def __init__(self):\n","        super().__init__()  # construct superclass first\n","        self.l1_w = get_weights(28*28, 10)  # Layer 1 weights\n","        self.l1_b = get_weights(10)         # Layer 1 bias\n","\n","# afte multiplication we are getting a 28row X 28 colm matrix and we \n","# need to flatten it out\n","# \n","        \n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)  # reshape/flatten the matrix to vector\n","        x = (x @ self.l1_w) + self.l1_b  # Linear Layer\n","        x = torch.log(softmax(x)) # Non-linear (LogSoftmax) Layer [takes e^ of \n","                                  #  o/p of linear layer\n","        return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l7vfxciLiddd","colab_type":"text"},"cell_type":"markdown","source":["We create our neural net and the optimizer.  (We will use the same loss and metrics from above)."]},{"metadata":{"id":"F_7iqCe0idde","colab_type":"code","colab":{}},"cell_type":"code","source":["net2 = LogReg().cuda()\n","opt=optim.Adam(net2.parameters())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mrB0nf2Jiddh","colab_type":"code","outputId":"84b9bd8e-3538-496c-97ce-6f38fd54430d","executionInfo":{"status":"ok","timestamp":1544482698923,"user_tz":-330,"elapsed":136039,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"cell_type":"code","source":["fit(net2, md, n_epochs=1, crit=loss, opt=opt, metrics=metrics)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8872aaea45e649c9a3c264a0d99e705f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["epoch      trn_loss   val_loss   accuracy   \n","    0      0.324897   0.281418   0.9206    \n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[array([0.28142]), 0.9206]"]},"metadata":{"tags":[]},"execution_count":82}]},{"metadata":{"id":"0qNWHitAiddm","colab_type":"code","colab":{}},"cell_type":"code","source":["# md.trn_dl is data loader training data loader and turn it into iterator\n","# so we can grab one at a time\n","dl = iter(md.trn_dl)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UynENoyAiddo","colab_type":"code","colab":{}},"cell_type":"code","source":["# grab one more thing from generator\n","xmb,ymb = next(dl)\n","\n","#returns tensor of size 64 784  mini batch size of 64"],"execution_count":0,"outputs":[]},{"metadata":{"id":"khocSwMNiddq","colab_type":"code","outputId":"1d5f7c34-a967-417a-cb32-e92024a6ab94","executionInfo":{"status":"ok","timestamp":1544482789555,"user_tz":-330,"elapsed":725,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"cell_type":"code","source":["'''\n","var x mini batch\n","pytorch will automatically differentiate the tensors but to do\n","that you need to keep record of all changes and chain multiply \n","them so use Variable : same as tensor but keeps track of changes\n","less strain\n","\n","'''\n","vxmb = Variable(xmb.cuda())\n","vxmb"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Variable containing:\n","-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n","-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n","-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n","          ...                          ...          \n","-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n","-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n","-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n","[torch.cuda.FloatTensor of size 64x784 (GPU 0)]"]},"metadata":{"tags":[]},"execution_count":85}]},{"metadata":{"id":"5pOOGXgMiddw","colab_type":"code","outputId":"d28d2e1c-cae2-4e2b-ef41-05f5cb362a9d","executionInfo":{"status":"ok","timestamp":1544482856654,"user_tz":-330,"elapsed":681,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":225}},"cell_type":"code","source":["preds = net2(vxmb).exp(); preds[:3]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Variable containing:\n","\n","Columns 0 to 5 \n"," 1.7534e-04  3.4398e-08  2.4604e-04  1.8413e-05  9.7433e-01  9.0401e-05\n"," 1.1642e-05  4.7637e-07  1.7783e-03  2.7140e-04  3.2470e-03  7.4107e-04\n"," 9.9872e-01  1.8375e-12  3.0201e-05  2.1513e-04  5.1182e-11  7.0344e-04\n","\n","Columns 6 to 9 \n"," 1.0183e-03  3.5089e-05  6.9588e-04  2.3391e-02\n"," 5.3063e-02  1.0884e-06  9.4018e-01  7.0657e-04\n"," 3.1102e-09  2.1748e-08  3.3508e-04  6.0495e-09\n","[torch.cuda.FloatTensor of size 3x10 (GPU 0)]"]},"metadata":{"tags":[]},"execution_count":86}]},{"metadata":{"id":"qGzoG_fWidd0","colab_type":"code","colab":{}},"cell_type":"code","source":["# pytorch does not take argmax have max max(1) returns values and \n","# their index so we are just taking indices down using max(1)[1]\n","\n","preds = preds.data.max(1)[1]; preds"],"execution_count":0,"outputs":[]},{"metadata":{"id":"idkLHPMyidd2","colab_type":"text"},"cell_type":"markdown","source":["Let's look at our predictions on the first eight images:"]},{"metadata":{"id":"DkuuWbofidd4","colab_type":"code","outputId":"662ee89e-6333-4306-ad95-8d04fd757b9e","executionInfo":{"status":"ok","timestamp":1544482865813,"user_tz":-330,"elapsed":1632,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":409}},"cell_type":"code","source":["preds = predict(net2, md.val_dl).argmax(1)\n","plots(x_imgs[:8], titles=preds[:8])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAr4AAAF0CAYAAADFHDo6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nes8xPAAAAABJRU5ErkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x7fa62b9e6e10>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"jzHsQvUKidd6","colab_type":"code","outputId":"56b9f8ec-45d8-4d19-b923-bb96be65c615","executionInfo":{"status":"ok","timestamp":1544484734888,"user_tz":-330,"elapsed":662,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":[" np.mean(preds == y_valid)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9206"]},"metadata":{"tags":[]},"execution_count":92}]},{"metadata":{"id":"0WYBtcIFidd-","colab_type":"text"},"cell_type":"markdown","source":["## Aside about Broadcasting and Matrix Multiplication"]},{"metadata":{"id":"Qgg3yWYwidd_","colab_type":"text"},"cell_type":"markdown","source":["Now let's dig in to what we were doing with `torch.matmul`: matrix multiplication.  First, let's start with a simpler building block: **broadcasting**."]},{"metadata":{"id":"ykldENNdideA","colab_type":"text"},"cell_type":"markdown","source":["### Element-wise operations "]},{"metadata":{"id":"g5Rqq00CideB","colab_type":"text"},"cell_type":"markdown","source":["Broadcasting and element-wise operations are supported in the same way by both numpy and pytorch.\n","\n","Operators (+,-,\\*,/,>,<,==) are usually element-wise.\n","\n","Examples of element-wise operations:"]},{"metadata":{"id":"s-gsFmDDideC","colab_type":"code","colab":{}},"cell_type":"code","source":["a = np.array([10, 6, -4])\n","b = np.array([2, 8, 7])\n","a,b"],"execution_count":0,"outputs":[]},{"metadata":{"id":"clxT1nyxideF","colab_type":"code","colab":{}},"cell_type":"code","source":["a + b"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5hYBbDb9ideN","colab_type":"code","colab":{}},"cell_type":"code","source":["(a < b).mean()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JRSML0HlideX","colab_type":"text"},"cell_type":"markdown","source":["### Broadcasting"]},{"metadata":{"id":"5d1IkWGNideb","colab_type":"text"},"cell_type":"markdown","source":["#### Broadcasting with a scalar"]},{"metadata":{"id":"yiBPGJTGidew","colab_type":"code","outputId":"5ac7e782-d54f-4629-e429-77fd1d7caefc","executionInfo":{"status":"ok","timestamp":1544485678777,"user_tz":-330,"elapsed":699,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["m = np.array([[1, 2, 3], [4,5,6], [7,8,9]]); m"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 2, 3],\n","       [4, 5, 6],\n","       [7, 8, 9]])"]},"metadata":{"tags":[]},"execution_count":93}]},{"metadata":{"id":"JzepP78Uide4","colab_type":"code","colab":{}},"cell_type":"code","source":["2*m # it is multiplication of a scalar which pretends to be a\n","    # var of higher dimensionality "],"execution_count":0,"outputs":[]},{"metadata":{"id":"1sM847VxidfA","colab_type":"text"},"cell_type":"markdown","source":["#### Broadcasting a vector to a matrix"]},{"metadata":{"id":"FfAZbCglidfO","colab_type":"text"},"cell_type":"markdown","source":["We can also broadcast a vector to a matrix:"]},{"metadata":{"id":"6qsyD6ZKidfP","colab_type":"code","outputId":"0c340908-10f3-419b-f159-b06dfbae5075","executionInfo":{"status":"ok","timestamp":1544485822942,"user_tz":-330,"elapsed":810,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["c = np.array([10,20,30]); c"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([10, 20, 30])"]},"metadata":{"tags":[]},"execution_count":99}]},{"metadata":{"id":"_mdMG4PEidfV","colab_type":"code","outputId":"4376afd0-9f4f-4460-e0bd-cc4985177e96","executionInfo":{"status":"ok","timestamp":1544485684114,"user_tz":-330,"elapsed":988,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["m + c"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[11, 22, 33],\n","       [14, 25, 36],\n","       [17, 28, 39]])"]},"metadata":{"tags":[]},"execution_count":95}]},{"metadata":{"id":"Lv36L3oNidfa","colab_type":"code","outputId":"929862d5-4dba-4223-d775-202d14792a93","executionInfo":{"status":"ok","timestamp":1544485765891,"user_tz":-330,"elapsed":705,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# to get new columns instead of rows[like above]\n"," # make it a col matrix using column_stack(c) "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[10, 20, 30]])"]},"metadata":{"tags":[]},"execution_count":98}]},{"metadata":{"id":"WDbWxbnjidfb","colab_type":"text"},"cell_type":"markdown","source":["Although numpy does this automatically, you can also use the `broadcast_to` method:"]},{"metadata":{"id":"OhAoXOdPidfd","colab_type":"code","outputId":"d9cd417f-1428-4bbd-e390-5a6c2f7325a7","executionInfo":{"status":"ok","timestamp":1544485854736,"user_tz":-330,"elapsed":646,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["c.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3,)"]},"metadata":{"tags":[]},"execution_count":100}]},{"metadata":{"id":"LLvowES7idff","colab_type":"code","outputId":"0bf900f9-fabf-456f-f405-9bd9077d87d9","executionInfo":{"status":"ok","timestamp":1544485856150,"user_tz":-330,"elapsed":905,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["np.broadcast_to(c[:,None], m.shape)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[10, 10, 10],\n","       [20, 20, 20],\n","       [30, 30, 30]])"]},"metadata":{"tags":[]},"execution_count":101}]},{"metadata":{"id":"6HUoVNqCidfj","colab_type":"code","outputId":"cfe8cf3c-a2d3-4529-e4ad-d2dd42e53633","executionInfo":{"status":"ok","timestamp":1544485857341,"user_tz":-330,"elapsed":923,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["np.broadcast_to(np.expand_dims(c,0), (3,3))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[10, 20, 30],\n","       [10, 20, 30],\n","       [10, 20, 30]])"]},"metadata":{"tags":[]},"execution_count":102}]},{"metadata":{"id":"SIIY6P8Cidfl","colab_type":"code","outputId":"a7403253-ea25-4d1a-e0da-dd0734de90b2","executionInfo":{"status":"ok","timestamp":1544485857709,"user_tz":-330,"elapsed":670,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["c.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3,)"]},"metadata":{"tags":[]},"execution_count":103}]},{"metadata":{"id":"Lk87N7EHidfm","colab_type":"code","outputId":"53b013cf-60f9-461f-f908-a009674a48b3","executionInfo":{"status":"ok","timestamp":1544485858220,"user_tz":-330,"elapsed":568,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["np.expand_dims(c,0).shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 3)"]},"metadata":{"tags":[]},"execution_count":104}]},{"metadata":{"id":"S4sMgRZDidfp","colab_type":"text"},"cell_type":"markdown","source":["The numpy `expand_dims` method lets us convert the 1-dimensional array `c` into a 2-dimensional array (although one of those dimensions has value 1)."]},{"metadata":{"id":"ukAnGeTDidfq","colab_type":"code","outputId":"46a001d3-8140-48a4-f161-289c2466cd7b","executionInfo":{"status":"ok","timestamp":1544485897537,"user_tz":-330,"elapsed":1082,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["np.expand_dims(c,0).shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 3)"]},"metadata":{"tags":[]},"execution_count":105}]},{"metadata":{"id":"9t15xBs4idfs","colab_type":"code","outputId":"d838ddfb-e9ca-4ad6-a159-c43cf69d4f4a","executionInfo":{"status":"ok","timestamp":1544485897542,"user_tz":-330,"elapsed":615,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["m + np.expand_dims(c,0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[11, 22, 33],\n","       [14, 25, 36],\n","       [17, 28, 39]])"]},"metadata":{"tags":[]},"execution_count":106}]},{"metadata":{"id":"bkmObquYidfu","colab_type":"code","outputId":"eabb12f0-e309-4218-c060-a00e1a510510","executionInfo":{"status":"ok","timestamp":1544485897856,"user_tz":-330,"elapsed":712,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["np.expand_dims(c,1)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[10],\n","       [20],\n","       [30]])"]},"metadata":{"tags":[]},"execution_count":107}]},{"metadata":{"id":"k2JoWm0Xidfw","colab_type":"code","outputId":"1cb52599-392d-4fb5-a1b0-da7b56ed58a5","executionInfo":{"status":"ok","timestamp":1544485898375,"user_tz":-330,"elapsed":657,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["c[:, None].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3, 1)"]},"metadata":{"tags":[]},"execution_count":108}]},{"metadata":{"id":"ID7LqzOcidfy","colab_type":"code","outputId":"6b8f28e4-cd07-4c7f-f66c-ee7119248301","executionInfo":{"status":"ok","timestamp":1544485899443,"user_tz":-330,"elapsed":894,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["m + np.expand_dims(c,1)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[11, 12, 13],\n","       [24, 25, 26],\n","       [37, 38, 39]])"]},"metadata":{"tags":[]},"execution_count":109}]},{"metadata":{"id":"OwYRHsY4idf0","colab_type":"code","outputId":"5b42b910-3605-4331-eae6-f85669c39ed9","executionInfo":{"status":"ok","timestamp":1544485900264,"user_tz":-330,"elapsed":872,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh6.googleusercontent.com/-iKW3ClKVQtg/AAAAAAAAAAI/AAAAAAAAAXA/acgkyzmJyyw/s64/photo.jpg","userId":"05163588411483717003"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["np.broadcast_to(np.expand_dims(c,1), (3,3))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[10, 10, 10],\n","       [20, 20, 20],\n","       [30, 30, 30]])"]},"metadata":{"tags":[]},"execution_count":110}]},{"metadata":{"id":"iSKpGgK2idf2","colab_type":"text"},"cell_type":"markdown","source":["#### Broadcasting Rules"]},{"metadata":{"id":"WxAWlXh1idf4","colab_type":"code","colab":{}},"cell_type":"code","source":["c[None]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tbR9KgXwidf6","colab_type":"code","colab":{}},"cell_type":"code","source":["c[:,None]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cSiGZO9Qidf7","colab_type":"code","colab":{}},"cell_type":"code","source":["c[None] > c[:,None]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YV2EPmetidf-","colab_type":"code","colab":{}},"cell_type":"code","source":["xg,yg = np.ogrid[0:5, 0:5]; xg,yg"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Oo0sAkqjidf_","colab_type":"code","colab":{}},"cell_type":"code","source":["xg+yg"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6MWRfYJwidgD","colab_type":"text"},"cell_type":"markdown","source":["When operating on two arrays, Numpy/PyTorch compares their shapes element-wise. It starts with the **trailing dimensions**, and works its way forward. Two dimensions are **compatible** when\n","\n","- they are equal, or\n","- one of them is 1\n","\n","Arrays do not need to have the same number of dimensions. For example, if you have a `256*256*3` array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:\n","\n","    Image  (3d array): 256 x 256 x 3\n","    Scale  (1d array):             3\n","    Result (3d array): 256 x 256 x 3\n","\n","The [numpy documentation](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html#general-broadcasting-rules) includes several examples of what dimensions can and can not be broadcast together."]},{"metadata":{"id":"LHEx3V6bidgF","colab_type":"text"},"cell_type":"markdown","source":["### Matrix Multiplication"]},{"metadata":{"id":"67c9ifqaidgF","colab_type":"text"},"cell_type":"markdown","source":["We are going to use broadcasting to define matrix multiplication."]},{"metadata":{"id":"fzrtmGFlidgG","colab_type":"code","colab":{}},"cell_type":"code","source":["m, c"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2QmiL0pvidgL","colab_type":"code","colab":{}},"cell_type":"code","source":["m @ c  # np.matmul(m, c)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ATwtuuapidgN","colab_type":"text"},"cell_type":"markdown","source":["We get the same answer using `torch.matmul`:"]},{"metadata":{"id":"eK3hG9YNidgN","colab_type":"code","colab":{}},"cell_type":"code","source":["T(m) @ T(c)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JpU6TvcfidgR","colab_type":"text"},"cell_type":"markdown","source":["The following is **NOT** matrix multiplication.  What is it?"]},{"metadata":{"id":"Cq-D-dBFidgR","colab_type":"code","colab":{}},"cell_type":"code","source":["m,c"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DgW6To1cidgT","colab_type":"code","colab":{}},"cell_type":"code","source":["m * c"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4qU4pCy7idga","colab_type":"code","colab":{}},"cell_type":"code","source":["(m * c).sum(axis=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LItZcx9uidgg","colab_type":"code","colab":{}},"cell_type":"code","source":["c"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ET93y0auidgk","colab_type":"code","colab":{}},"cell_type":"code","source":["np.broadcast_to(c, (3,3))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AnOqM6-yidgr","colab_type":"text"},"cell_type":"markdown","source":["From a machine learning perspective, matrix multiplication is a way of creating features by saying how much we want to weight each input column.  **Different features are different weighted averages of the input columns**. \n","\n","The website [matrixmultiplication.xyz](http://matrixmultiplication.xyz/) provides a nice visualization of matrix multiplcation"]},{"metadata":{"id":"xUdfRCVnidgr","colab_type":"code","colab":{}},"cell_type":"code","source":["n = np.array([[10,40],[20,0],[30,-5]]); n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9glHX9XUidgv","colab_type":"code","colab":{}},"cell_type":"code","source":["m"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5jUcSr98idgx","colab_type":"code","colab":{}},"cell_type":"code","source":["m @ n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6a51MKglidg0","colab_type":"code","colab":{}},"cell_type":"code","source":["(m * n[:,0]).sum(axis=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x9dPCgbridg1","colab_type":"code","colab":{}},"cell_type":"code","source":["(m * n[:,1]).sum(axis=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WlsbsCu4idg4","colab_type":"text"},"cell_type":"markdown","source":["## Writing Our Own Training Loop"]},{"metadata":{"id":"YATq56Zsidg4","colab_type":"text"},"cell_type":"markdown","source":["As a reminder, this is what we did above to write our own logistic regression class (as a pytorch neural net):"]},{"metadata":{"id":"x_AWz64Midg5","colab_type":"code","colab":{}},"cell_type":"code","source":["# Our code from above\n","class LogReg(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.l1_w = get_weights(28*28, 10)  # Layer 1 weights\n","        self.l1_b = get_weights(10)         # Layer 1 bias\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)\n","        x = x @ self.l1_w + self.l1_b \n","        return torch.log(softmax(x))\n","\n","net2 = LogReg().cuda()\n","opt=optim.Adam(net2.parameters())\n","\n","fit(net2, md, n_epochs=1, crit=loss, opt=opt, metrics=metrics)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2bI5Uudvidg9","colab_type":"text"},"cell_type":"markdown","source":["Above, we are using the fastai method `fit` to train our model.  Now we will try writing the training loop ourselves.\n","\n","**Review question:** What does it mean to train a model?"]},{"metadata":{"id":"GuZHAfjxidg9","colab_type":"text"},"cell_type":"markdown","source":["We will use the LogReg class we created, as well as the same loss function, learning rate, and optimizer as before:"]},{"metadata":{"id":"1xMHddvmidg9","colab_type":"code","colab":{}},"cell_type":"code","source":["net2 = LogReg().cuda()\n","loss=nn.NLLLoss()\n","learning_rate = 1e-3\n","optimizer=optim.Adam(net2.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7O3kqznRidg-","colab_type":"text"},"cell_type":"markdown","source":["md is the ImageClassifierData object we created above.  We want an iterable version of our training data (**question**: what does it mean for something to be iterable?):"]},{"metadata":{"id":"VY08Psfiidg_","colab_type":"code","colab":{}},"cell_type":"code","source":["dl = iter(md.trn_dl) # Data loader"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DlosvXtoidhA","colab_type":"text"},"cell_type":"markdown","source":["First, we will do a **forward pass**, which means computing the predicted y by passing x to the model."]},{"metadata":{"id":"3URTnuRgidhC","colab_type":"code","colab":{}},"cell_type":"code","source":["xt, yt = next(dl)\n","y_pred = net2(Variable(xt).cuda())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DDy6GCIaidhE","colab_type":"text"},"cell_type":"markdown","source":["We can check the loss:"]},{"metadata":{"id":"huBtbJRridhG","colab_type":"code","colab":{}},"cell_type":"code","source":["l = loss(y_pred, Variable(yt).cuda())\n","print(l)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"84NWnXWpidhI","colab_type":"text"},"cell_type":"markdown","source":["We may also be interested in the accuracy.  We don't expect our first predictions to be very good, because the weights of our network were initialized to random values.  Our goal is to see the loss decrease (and the accuracy increase) as we train the network:"]},{"metadata":{"id":"UDooRLdlidhI","colab_type":"code","colab":{}},"cell_type":"code","source":["np.mean(to_np(y_pred).argmax(axis=1) == to_np(yt))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TkOsnuwridhL","colab_type":"text"},"cell_type":"markdown","source":["Now we will use the optimizer to calculate which direction to step in.  That is, how should we update our weights to try to decrease the loss?\n","\n","Pytorch has an automatic differentiation package ([autograd](http://pytorch.org/docs/master/autograd.html)) that takes derivatives for us, so we don't have to calculate the derivative ourselves!  We just call `.backward()` on our loss to calculate the direction of steepest descent (the direction to lower the loss the most)."]},{"metadata":{"id":"ykTCzJMOidhL","colab_type":"code","colab":{}},"cell_type":"code","source":["# Before the backward pass, use the optimizer object to zero all of the\n","# gradients for the variables it will update (which are the learnable weights\n","# of the model)\n","optimizer.zero_grad()\n","\n","# Backward pass: compute gradient of the loss with respect to model parameters\n","l.backward()\n","\n","# Calling the step function on an Optimizer makes an update to its parameters\n","optimizer.step()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gWEcWvMnidhO","colab_type":"text"},"cell_type":"markdown","source":["Now, let's make another set of predictions and check if our loss is lower:"]},{"metadata":{"id":"fpIohfnJidhO","colab_type":"code","colab":{}},"cell_type":"code","source":["xt, yt = next(dl)\n","y_pred = net2(Variable(xt).cuda())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gUEqnlHAidhT","colab_type":"code","colab":{}},"cell_type":"code","source":["l = loss(y_pred, Variable(yt).cuda())\n","print(l)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_gd5N0_9idhV","colab_type":"text"},"cell_type":"markdown","source":["Note that we are using **stochastic** gradient descent, so the loss is not guaranteed to be strictly better each time.  The stochasticity comes from the fact that we are using **mini-batches**; we are just using 64 images to calculate our prediction and update the weights, not the whole dataset."]},{"metadata":{"id":"qAKw2zOHidhV","colab_type":"code","colab":{}},"cell_type":"code","source":["np.mean(to_np(y_pred).argmax(axis=1) == to_np(yt))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dHBc8jFiidhe","colab_type":"text"},"cell_type":"markdown","source":["If we run several iterations in a loop, we should see the loss decrease and the accuracy increase with time."]},{"metadata":{"id":"UzGR4pTQidhf","colab_type":"code","colab":{}},"cell_type":"code","source":["for t in range(100):\n","    xt, yt = next(dl)\n","    y_pred = net2(Variable(xt).cuda())\n","    l = loss(y_pred, Variable(yt).cuda())\n","    \n","    if t % 10 == 0:\n","        accuracy = np.mean(to_np(y_pred).argmax(axis=1) == to_np(yt))\n","        print(\"loss: \", l.data[0], \"\\t accuracy: \", accuracy)\n","\n","    optimizer.zero_grad()\n","    l.backward()\n","    optimizer.step()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tuIIRtApidhh","colab_type":"text"},"cell_type":"markdown","source":["### Put it all together in a training loop"]},{"metadata":{"id":"vU2e5CYMidhh","colab_type":"code","colab":{}},"cell_type":"code","source":["def score(x, y):\n","    y_pred = to_np(net2(V(x)))\n","    return np.sum(y_pred.argmax(axis=1) == to_np(y))/len(y_pred) \n","  \n","  # return statement is generator and "],"execution_count":0,"outputs":[]},{"metadata":{"id":"mAvKpopGidhl","colab_type":"code","colab":{}},"cell_type":"code","source":["'''\n","variable can track all the steps to get computed \n","autograd in pytorch and variable class search\n","\n","\n","\n","'''\n","\n","\n","net2 = LogReg().cuda()\n","loss=nn.NLLLoss()\n","learning_rate = 1e-2\n","optimizer=optim.SGD(net2.parameters(), lr=learning_rate)\n","\n","for epoch in range(1):  # go through 1 epoch\n","    losses=[]\n","    dl = iter(md.trn_dl) # convert training loader to iterator\n","    for t in range(len(dl)):\n","        # Forward pass: compute predicted y and loss by passing x to the model.\n","        xt, yt = next(dl)\n","        y_pred = net2(V(xt)) # converting into variable V()\n","        l = loss(y_pred, V(yt))\n","        losses.append(l)\n","\n","        # Before the backward pass, use the optimizer object to zero all of the\n","        # gradients for the variables it will update (which are the learnable weights of the model)\n","        optimizer.zero_grad()\n","\n","        # Backward pass: compute gradient of the loss with respect to model parameters\n","        l.backward()\n","\n","        # Calling the step function on an Optimizer makes an update to its parameters\n","        optimizer.step()\n","    \n","    val_dl = iter(md.val_dl)\n","    val_scores = [score(*next(val_dl)) for i in range(len(val_dl))]\n","    print(np.mean(val_scores))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CUXew8Wkidhn","colab_type":"text"},"cell_type":"markdown","source":["## Stochastic Gradient Descent"]},{"metadata":{"id":"2inPzxbAidhn","colab_type":"text"},"cell_type":"markdown","source":["Nearly all of deep learning is powered by one very important algorithm: **stochastic gradient descent (SGD)**. SGD can be seeing as an approximation of **gradient descent (GD)**. In GD you have to run through all the samples in your training set to do a single itaration. In SGD you use only a subset of training samples to do the update for a parameter in a particular iteration. The subset used in each iteration is called a batch or minibatch.\n","\n","Now, instead of using the optimizer, we will do the optimization ourselves!"]},{"metadata":{"id":"bt1nOpbOidhn","colab_type":"code","colab":{}},"cell_type":"code","source":["net2 = LogReg().cuda()\n","loss_fn=nn.NLLLoss()\n","lr = 1e-2\n","w,b = net2.l1_w,net2.l1_b\n","\n","for epoch in range(1):\n","    losses=[]\n","    dl = iter(md.trn_dl)\n","    for t in range(len(dl)):\n","        xt, yt = next(dl)\n","        y_pred = net2(V(xt))\n","        l = loss(y_pred, Variable(yt).cuda())\n","        losses.append(loss)\n","\n","        # Backward pass: compute gradient of the loss with respect to model parameters\n","        l.backward()\n","        w.data -= w.grad.data * lr\n","        b.data -= b.grad.data * lr\n","        \n","        w.grad.data.zero_()\n","        b.grad.data.zero_()   \n","\n","    val_dl = iter(md.val_dl)\n","    val_scores = [score(*next(val_dl)) for i in range(len(val_dl))]\n","    print(np.mean(val_scores))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"q9WKBm5jidhr","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}